= Neo4j Kafka Integrations



== Neo4j-Kafka

Stream transaction event handler events to a Kafka topic

Ideas based on a now removed repository from workday.

Currently for kafka


=== Installation

Build locally
// todo release

----
mvn clean install
----

2. Copy `target/neo4j-kafka-*.jar` into `$NEO4J_HOME/plugins`
3. Restart Neo4j

=== Configuration

You can set the following configuration values in your `neo4j.conf`, here are the defaults.

.neo4j.conf
----
kafka.zookeeper.connect=localhost:2181
kafka.bootstrap.servers=localhost:9092
kafka.acks=1
kafka.num.partitions=1
kafka.retries=2
kafka.batch.size=16384
kafka.buffer.memory=33554432
kafka.reindex.batch.size=1000
kafka.session.timeout.ms=15000
kafka.connection.timeout.ms=10000
kafka.replication=1

kafka.topic=neo4j
kafka.group.id=neo4j
----

See the https://kafka.apache.org/documentation/#brokerconfigs[Apache Kafka documentation] for details on these settings.

=== Testing

Following https://kafka.apache.org/quickstart[these instructions].

1. Download & Unzip Kafka

2. Run Zookeeper, server and a test consumer.

----
bin/zookeeper-server-start.sh config/zookeeper.properties

bin/kafka-server-start.sh config/server.properties

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic neo4j [--from-beginning]
----

=== Next Steps

* Send data asynchronously
* Use Kafka transactions for batching updates


== Neo4j-Kafka-Consumer

1. Read Kafka records from given topic(s)
2. Treat records as input parameters
3. Uses configured Cypher statements to merge them into the graph.

=== Next Steps

1. Implement as Kernel Extension
2. Implement as Bolt Client

== Neo4j-Kafka-Connect

Implementation for a Kafka Sink / Source

based on work in https://github.com/pegerto/kafka-connect-neo4j

=== Next Steps

1. Implement for Bolt connection
2. Figure out if kernel extension makes sense
